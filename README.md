# TS-Rule-Backend

ä¸€ä¸ªåŸºäº Python çš„è§„åˆ™å¼•æ“åç«¯ç³»ç»Ÿï¼Œæ”¯æŒä» Redis åŠ è½½æ•°æ®å¹¶è¿›è¡Œå¤æ‚çš„æ•°æ®å¤„ç†å’Œåˆ†æã€‚

## ğŸš€ ä¸»è¦åŠŸèƒ½

### 1. æ•°æ®åŠ è½½ (Data Loading)
- æ”¯æŒä» Redis åŠ è½½å¤šç§ç±»å‹çš„æ•°æ®
- æ”¯æŒæ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–æ€§èƒ½
- æ”¯æŒå ä½ç¬¦å’ŒåŠ¨æ€å‚æ•°æ›¿æ¢
- æ”¯æŒæ—¶é—´åºåˆ—æ•°æ®å¤„ç†

### 2. è§„åˆ™å¼•æ“ (Rule Engine)
- æ”¯æŒå››ç§èŠ‚ç‚¹ç±»å‹ï¼šstartã€logicã€gateã€collection
- æ”¯æŒèŠ‚ç‚¹é—´çš„ä¾èµ–å…³ç³»ç®¡ç†
- æ”¯æŒæ•°æ®æµè¿½è¸ªå’ŒéªŒè¯

### 3. æ•°æ®ç±»å‹æ”¯æŒ
- **value**: ç®€å•å€¼ç±»å‹ (int, double, string, boolean)
- **json**: JSON å¯¹è±¡ç±»å‹
- **timeseries**: æ—¶é—´åºåˆ—æ•°æ® (DataFrame)
- **densets**: åˆ†éš”ç¬¦åˆ†éš”çš„æ•°æ® (DataFrame)

### 4. æ•°æ®éªŒè¯ (Data Validation)
- æ”¯æŒç±»å‹è½¬æ¢å’Œæ£€æŸ¥
- æ”¯æŒ DataFrame åˆ—ç±»å‹éªŒè¯

## ğŸ“ é¡¹ç›®ç»“æ„

```
ts-rule-backend/
â”œâ”€â”€ core/                    # è§„åˆ™å¼•æ“æ ¸å¿ƒ
â”‚   â”œâ”€â”€ engine.py           # è§„åˆ™å¼•æ“ä¸»ç±»
â”‚   â”œâ”€â”€ nodes.py            # èŠ‚ç‚¹å®šä¹‰
â”‚   â”œâ”€â”€ data_flow.py        # æ•°æ®æµç®¡ç†
â”‚   â””â”€â”€ json_helper.py      # JSON å·¥å…·
â”œâ”€â”€ data/                   # æ•°æ®åŠ è½½æ¨¡å—
â”‚   â”œâ”€â”€ dataloader.py       # æ•°æ®åŠ è½½å™¨
â”‚   â””â”€â”€ redis_connector.py  # Redis è¿æ¥å™¨
â”œâ”€â”€ type/                   # ç±»å‹ç³»ç»Ÿ
â”‚   â”œâ”€â”€ schema.py           # Schema å®šä¹‰
â”‚   â”œâ”€â”€ validator.py        # æ•°æ®éªŒè¯å™¨
â”‚   â””â”€â”€ serializer.py       # åºåˆ—åŒ–å·¥å…·
â”œâ”€â”€ utils/                  # å·¥å…·æ¨¡å—
â”‚   â””â”€â”€ datetime_parser.py  # æ—¥æœŸæ—¶é—´è§£æ
â”œâ”€â”€ test/                   # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ example_forecast.py     # é¢„æµ‹ç¤ºä¾‹
â”œâ”€â”€ example_engine.py       # å¼•æ“ç¤ºä¾‹
â””â”€â”€ requirements.txt        # ä¾èµ–åŒ…
```

## ğŸ› ï¸ å®‰è£…å’Œè®¾ç½®

### 1. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 2. å¯åŠ¨ Redis
```bash
# macOS
brew services start redis

# Ubuntu
sudo systemctl start redis

# Docker
docker run -p 6379:6379 redis:latest
```

## ğŸ“– ä½¿ç”¨æŒ‡å—

### 1. æ•°æ®é…ç½® (Data Config)

æ•°æ®é…ç½®å®šä¹‰äº†ä» Redis åŠ è½½æ•°æ®çš„è§„åˆ™ï¼š

```python
data_config = {
    "namespace": "sams_cloud_demand_fcst_tn",
    "placeholder": [
        {"name": "store_nbr", "description": "é—¨åº—å·"},
        {"name": "item_nbr", "description": "å•†å“å·"},
    ],
    "variable": [
        {
            "name": "dim_store",
            "description": "é—¨åº—ç»´åº¦ä¿¡æ¯",
            "namespace": "sams_cloud",
            "redis_config": {
                "prefix": [
                    {"key": "store_nbr", "value": "${store_nbr}"}
                ],
                "field": "dim_store",
                "type": "json"
            }
        },
        {
            "name": "forecast_data",
            "description": "é¢„æµ‹æ•°æ®",
            "redis_config": {
                "prefix": [
                    {"key": "store_nbr", "value": "${store_nbr}"},
                    {"key": "item_nbr", "value": "${item_nbr}"}
                ],
                "field": "forecast_data",
                "type": "densets",
                "split": ",",
                "schema": "job_date:string,fcst_date:string,fcst_qty:double,etl_time:string"
            }
        }
    ]
}
```

### 2. è§„åˆ™å¼•æ“ (Rule Engine)

åˆ›å»ºå’Œæ‰§è¡Œè§„åˆ™å¼•æ“ï¼š

```python
from core.engine import RuleEngine
from core.nodes import LogicNode, GateNode, CollectionNode

# åˆ›å»ºå¼•æ“
engine = RuleEngine("my_engine")

# åˆ›å»ºèŠ‚ç‚¹
logic_node = LogicNode("process_data")
logic_node.set_logic("""
# å¤„ç†æ•°æ®
result = input_data * 2
trend = result.mean()
""")
logic_node.set_tracked_variables(["result", "trend"])

# æ·»åŠ ä¾èµ–å…³ç³»
engine.add_dependency(None, logic_node)

# æ‰§è¡Œå¼•æ“
results = engine.execute(
    job_date="2025-01-01 00:00:00",
    placeholders={"store_nbr": "123", "item_nbr": "456"},
    variables=loaded_data
)
```

### 3. èŠ‚ç‚¹ç±»å‹

#### StartNode
èµ·å§‹èŠ‚ç‚¹ï¼Œè‡ªåŠ¨åˆ›å»ºï¼š
```python
# è‡ªåŠ¨åˆ›å»ºï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®
```

#### LogicNode
é€»è¾‘å¤„ç†èŠ‚ç‚¹ï¼š
```python
logic_node = LogicNode("process")
logic_node.set_logic("""
# Python ä»£ç 
result = data * 2
""")
logic_node.set_tracked_variables(["result"])
```

#### GateNode
æ¡ä»¶åˆ¤æ–­èŠ‚ç‚¹ï¼š
```python
gate_node = GateNode("check_condition")
gate_node.set_condition("value > 100")
```

#### CollectionNode
æ•°æ®æ”¶é›†èŠ‚ç‚¹ï¼š
```python
collection_node = CollectionNode("collect")
collection_node.set_logic("""
# æ”¶é›†ä¸Šæ¸¸èŠ‚ç‚¹çš„è¾“å‡º
import pandas as pd
df_concat = pd.concat([collection[node_name]['output'] for node_name in collection])
output = df_concat.groupby('date').sum()
""")
collection_node.set_tracked_variables(["output"])
```

### 4. æ•°æ®ç±»å‹

#### Value ç±»å‹
```python
# ç®€å•å€¼
"type": "value"
```

#### JSON ç±»å‹
```python
# JSON å¯¹è±¡
"type": "json"
```

#### Timeseries ç±»å‹
```python
# æ—¶é—´åºåˆ—æ•°æ®
"type": "timeseries",
"from_datetime": "${yyyy-MM-dd}",
"to_datetime": "${yyyy-MM-dd+6d}",
"drop_duplicate": "keep_latest"  # "none" æˆ– "keep_latest"
```

#### Densets ç±»å‹
```python
# åˆ†éš”ç¬¦åˆ†éš”çš„æ•°æ®
"type": "densets",
"split": ",",
"schema": "job_date:string,fcst_date:string,fcst_qty:double,etl_time:string"
```

### 5. Schema éªŒè¯

æ”¯æŒä¸¤ç§ schema æ ¼å¼ï¼š

#### ç®€å•å€¼ Schema
```python
"trend": "double"
"name": "string"
"count": "int"
"active": "boolean"
```

#### DataFrame Schema
```python
"forecast": "ds:string,fcst_qty:double,etl_time:string"
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. æ‰¹é‡æ•°æ®åŠ è½½
```python
# ä½¿ç”¨æ‰¹é‡åŠ è½½æé«˜æ€§èƒ½
loaded_data = loader.load_data_batch(data_config, placeholders, job_datetime)
```

### 2. åŠ¨æ€å‚æ•°æ›¿æ¢
æ”¯æŒå¤šç§åŠ¨æ€å‚æ•°ï¼š
- `${yyyy-MM-dd}`: å½“å‰æ—¥æœŸ
- `${yyyy-MM-dd+6d}`: 6å¤©å
- `${yyyy-MM-dd-1d}`: 1å¤©å‰
- `${store_nbr}`: å ä½ç¬¦æ›¿æ¢

### 3. æ•°æ®æµè¿½è¸ª
```python
# è·å–èŠ‚ç‚¹çš„æ•°æ®æµä¸Šä¸‹æ–‡
context = engine.get_node_flow_context("node_name")
values = engine.get_node_flow_context_values("node_name")
```

### 4. æ‰§è¡Œæ‘˜è¦
```python
summary = engine.get_execution_summary()
print(f"æˆåŠŸç‡: {summary['success_rate']:.2%}")
```

## ğŸ“ ç¤ºä¾‹

### å®Œæ•´ç¤ºä¾‹
å‚è€ƒ `example_forecast.py` æŸ¥çœ‹å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹ã€‚

### ç®€å•ç¤ºä¾‹
```python
from data.redis_connector import RedisConnector
from data.dataloader import DataLoader
from core.engine import RuleEngine
from core.nodes import LogicNode

# åˆå§‹åŒ–
connector = RedisConnector()
loader = DataLoader(connector)
engine = RuleEngine("demo")

# åŠ è½½æ•°æ®
data_config = {...}  # ä½ çš„æ•°æ®é…ç½®
placeholders = {"store_nbr": "123"}
loaded_data = loader.load_data(data_config, placeholders, "2025-01-01 00:00:00")

# åˆ›å»ºè§„åˆ™
node = LogicNode("process")
node.set_logic("result = data * 2")
engine.add_dependency(None, node)

# æ‰§è¡Œ
results = engine.execute("2025-01-01 00:00:00", placeholders, loaded_data)
```

## ğŸ§ª æµ‹è¯•

è¿è¡Œæµ‹è¯•ï¼š
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python run_tests.py

# è¿è¡Œç‰¹å®šæµ‹è¯•
cd test && python test_densets.py

# ä½¿ç”¨ pytest
pytest test/ -v
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

1. **æ‰¹é‡æŸ¥è¯¢**: ä½¿ç”¨ `load_data_batch()` è¿›è¡Œæ‰¹é‡æ•°æ®åŠ è½½
2. **è¿æ¥æ± **: Redis è¿æ¥å™¨æ”¯æŒè¿æ¥æ± 
3. **ç¼“å­˜**: æ”¯æŒæ•°æ®ç¼“å­˜å’Œ TTL è®¾ç½®
4. **å¹¶è¡Œå¤„ç†**: è§„åˆ™å¼•æ“æ”¯æŒèŠ‚ç‚¹å¹¶è¡Œæ‰§è¡Œ

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Redis è¿æ¥å¤±è´¥**
   - æ£€æŸ¥ Redis æœåŠ¡æ˜¯å¦å¯åŠ¨
   - æ£€æŸ¥è¿æ¥å‚æ•°æ˜¯å¦æ­£ç¡®

2. **æ•°æ®åŠ è½½å¤±è´¥**
   - æ£€æŸ¥ data_config é…ç½®
   - æ£€æŸ¥å ä½ç¬¦æ˜¯å¦æ­£ç¡®æ›¿æ¢
   - æ£€æŸ¥ Redis ä¸­æ˜¯å¦å­˜åœ¨å¯¹åº”æ•°æ®

3. **è§„åˆ™å¼•æ“æ‰§è¡Œå¤±è´¥**
   - æ£€æŸ¥èŠ‚ç‚¹ä¾èµ–å…³ç³»
   - æ£€æŸ¥ schema éªŒè¯
   - æŸ¥çœ‹è¯¦ç»†çš„é”™è¯¯æ—¥å¿—

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤ Issue æˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚ 